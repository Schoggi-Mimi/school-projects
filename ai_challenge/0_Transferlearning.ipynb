{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c29f13-daa8-4a74-bcb3-1e5c3418db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm.auto import tqdm\n",
    "import logging\n",
    "import preprocessing\n",
    "import base_model\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f86be-07ef-409c-9a23-ef60fbb462a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_MODE = True\n",
    "TEST_CHUNK_SIZE = 100_000\n",
    "FREEZE_LAYERS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3e2af-57ae-4264-8b6e-50d029fa2df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE:\n",
    "    train = pd.read_csv('../data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f40c8c1-fb1c-4893-9d81-62f15d650532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'yangheng/RNA-RoBERTa-v0.1'\n",
    "model_name = 'zhihan1996/DNABERT-2-117M'\n",
    "model_name_end = model_name.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e7900-a72b-45ea-bd44-0528fa2a4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=457*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7fb8c-3936-433a-91e8-9ef28fa8ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = preprocessing.Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a49a4-fb49-4f77-8409-a51714fdcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE:\n",
    "    train_sets, preprocessing_config = preprocessor.prepare_xy_split(train, \n",
    "                              categorical=lambda x: tokenizer(x, truncation=True, padding='max_length', max_length=457, return_tensors='pt'), \n",
    "                              shuffle=True, validation_split=None, \n",
    "                              batch_size=16, filter_noise=True, dual_model=False, k_fold=5, \n",
    "                              structure=False, clip=True, weighted_loss=None, additive_weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12076f72-ec5c-419e-b3f8-82b8acf0d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE:\n",
    "    print(train_sets[0][1][0].dataset[0][0].shape, train_sets[0][1][0].dataset[0][1].shape, train_sets[0][1][0].dataset[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d45af6-0f28-4793-a148-8f7ab728b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE and FREEZE_LAYERS:\n",
    "    # Freeze all\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Replace last layer\n",
    "    model.classifier.dense = nn.Linear(in_features=model.config.hidden_size, out_features=model.config.hidden_size)\n",
    "    model.classifier.out_proj = nn.Linear(in_features=model.config.hidden_size, out_features=457*2)\n",
    "    \n",
    "    # Require last layer gradients\n",
    "    for param in model.classifier.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec3176-0c9c-491d-822f-d6364b107313",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "NUM_EPOCHS = 3\n",
    "optimizer = AdamW(model.parameters(), lr=LR)\n",
    "scheduler = CyclicLR(optimizer, base_lr=LR/10, max_lr=LR, cycle_momentum=False, mode='triangular2')\n",
    "model = base_model.BaseModel(optimizer, model, f'PRETRAINED-{model_name_end}.pth', \n",
    "                            scheduler=scheduler, enable_wandb=True, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5747a834-85f7-47f2-94a1-915a63918b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE:\n",
    "    experiment_type, train_data_loader, validation_data_loader = train_sets[0]\n",
    "    print(f'Model fit {experiment_type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8652cd8-3812-4841-8b63-5cee860f16aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAINING_MODE:\n",
    "    tags = ['Transferlearning']\n",
    "    if FREEZE_LAYERS:\n",
    "        tags += ['Frozen']\n",
    "        \n",
    "    model.fit(\n",
    "        train_data_loader,\n",
    "        validation_data_loader,\n",
    "        experiment_type=experiment_type,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=True,\n",
    "        preprocessing_config=preprocessing_config,\n",
    "        tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4c449-0de0-445b-9a7f-ac4a2a9b7481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING_MODE:\n",
    "    test = pd.read_csv('../data/test_sequences.csv')\n",
    "    #test = test.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e86131-0e79-4944-b01e-292a760e1633",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING_MODE:\n",
    "    model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94eb6dc-6584-4480-8f64-19a45d18c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TRAINING_MODE:\n",
    "    final_outputs = pd.DataFrame()\n",
    "    final_outputs.index.name = 'id'\n",
    "    experiment_types = ['DMS_AND_2A3_MaP']\n",
    "    \n",
    "    for experiment_type in experiment_types:\n",
    "        print(f'Model prediction {experiment_type}')\n",
    "        \n",
    "        new_init = True\n",
    "        all_predictions = []\n",
    "        test_size = test.shape[0]\n",
    "        for start_chunk in tqdm(range(0, test_size, TEST_CHUNK_SIZE)):\n",
    "            s_index, e_index = start_chunk, start_chunk + TEST_CHUNK_SIZE\n",
    "            if e_index > test_size:\n",
    "                e_index = test_size\n",
    "                \n",
    "            finish_wandb = False\n",
    "            if e_index == test_size:\n",
    "                finish_wandb = True\n",
    "                \n",
    "            test_set = preprocessor.prepare_prediction_dataset(test.iloc[s_index:e_index], \n",
    "                                batch_size=256,\n",
    "                                categorical=lambda x: tokenizer(x, truncation=True, padding='max_length', \n",
    "                                                                max_length=457, return_tensors='pt'), \n",
    "                                structure=False, verbose=False)\n",
    "        \n",
    "            final_predictions = model.predict(test_set, single_model_mode=True, new_init=new_init, finish_wandb=finish_wandb)\n",
    "            del test_set\n",
    "            new_init = False\n",
    "\n",
    "            final_predictions = final_predictions.cpu().numpy()\n",
    "            all_predictions.append(final_predictions)\n",
    "            del final_predictions\n",
    "            gc.collect()\n",
    "        \n",
    "        final_predictions = np.vstack(all_predictions)\n",
    "\n",
    "        final_outputs[f'reactivity_DMS_MaP'] = final_predictions[:,0]\n",
    "        final_outputs[f'reactivity_2A3_MaP'] = final_predictions[:,1]\n",
    "        del final_predictions\n",
    "        del model\n",
    "        \n",
    "        gc.collect()\n",
    "    final_outputs.clip(0.0, 1.0, inplace=True)\n",
    "    final_outputs.to_csv(f'PRETRAINING-{model_name_end}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "036af3f7-70d1-45b3-94b1-565aa42110c6",
   "metadata": {},
   "source": [
    "from importlib import reload\n",
    "reload(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c414c-e35e-4e54-a699-df48d5c63e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
