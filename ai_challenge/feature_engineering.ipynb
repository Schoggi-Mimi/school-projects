{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e285f87c",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### Compute Structure / Loop Data for Train/Test\n",
    "\n",
    "> Note: Only run this notebook if you dont have the data files already(train_newfeat2.csv, test_newfeat2.csv).\n",
    "> This will take a long time (>8h).\n",
    "> Not compatible with Windows b.c. of missing library builds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4086c58-7392-4527-86d1-62d0529f6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.name == 'nt':\n",
    "    raise NotImplementedError('No Builds for Windows')\n",
    "\n",
    "!pip install -q --upgrade arnie forgi\n",
    "!conda install -y -q -c bioconda viennarna eternafold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f44ff6-e10a-4186-b2ee-18eb677b404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env ETERNAFOLD_PATH=/opt/conda/bin/eternafold-bin\n",
    "%env ETERNAFOLD_PARAMETERS=/opt/conda/lib/eternafold-lib/parameters/EternaFoldParams.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d73c6-f280-4530-ab92-442405639b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df1 = pd.read_csv('../data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafe9ea9-54de-4594-8055-275935e1f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sneak peak\n",
    "print(df1.shape)\n",
    "if ~ df1.isnull().values.any(): print('No missing values')\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af936a6a-0333-4905-95e0-2ea69744d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "df = df1.copy()\n",
    "print(df.shape, df1.shape)\n",
    "del df1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0315bffa-9258-4cf9-a5e2-fb43e5a64e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from arnie.mfe import mfe\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# Function to apply mfe to a chunk of data\n",
    "def apply_mfe(chunk):\n",
    "    chunk['structure'] = chunk['sequence'].apply(lambda x: mfe(x, package='eternafold'))\n",
    "    return chunk\n",
    "\n",
    "# Estimate memory usage of a single row in the DataFrame\n",
    "sample_row = df.iloc[0:1]\n",
    "sample_row_mem = sample_row.memory_usage(index=True, deep=True).sum()\n",
    "\n",
    "# Calculate a reasonable chunk size based on available memory and individual row memory usage\n",
    "total_memory = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')\n",
    "print(f'Total memory: {total_memory}')\n",
    "max_chunk_size = int(0.8 * (total_memory / sample_row_mem))\n",
    "chunk_size = min(max_chunk_size, len(df) // multiprocessing.cpu_count())\n",
    "print(f'Chunk size: {chunk_size}, Max chunk size: {max_chunk_size}')\n",
    "\n",
    "# Split DataFrame into chunks based on the adjusted chunk size\n",
    "df_chunks = [df[i:i + chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "print(f'Length of DataFrame chunks: {len(df_chunks)}')\n",
    "\n",
    "# Process chunks in parallel with a progress bar\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(apply_mfe, df_chunks), total=len(df_chunks), desc='Processing'))\n",
    "\n",
    "result_df = pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fe70e-ca7e-409e-a89e-df737391ccc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sneak peak\n",
    "print(result_df.shape)\n",
    "if ~ result_df.isnull().values.any(): print('No missing values')\n",
    "result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d967977-3656-40e7-9aca-5ab2eaf9240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('train_newfeat1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064a260-6703-4c7c-9428-6e2701a366ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import forgi\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def label_sequence(seq, bg):\n",
    "    for stem in bg.stem_iterator():\n",
    "        for rn in bg.define_residue_num_iterator(stem):\n",
    "            seq = seq[:rn - 1] + 'S' + seq[rn:]\n",
    "    for iloop in bg.iloop_iterator():\n",
    "        for rn in bg.define_residue_num_iterator(iloop):\n",
    "            seq = seq[:rn - 1] + 'I' + seq[rn:]\n",
    "    for mloop in bg.mloop_iterator():\n",
    "        for rn in bg.define_residue_num_iterator(mloop):\n",
    "            seq = seq[:rn - 1] + 'M' + seq[rn:]\n",
    "    for hloop in bg.hloop_iterator():\n",
    "        for rn in bg.define_residue_num_iterator(hloop):\n",
    "            seq = seq[:rn - 1] + 'H' + seq[rn:]\n",
    "    for floop in bg.floop_iterator():\n",
    "        for rn in bg.define_residue_num_iterator(floop):\n",
    "            seq = seq[:rn - 1] + 'E' + seq[rn:]\n",
    "    for tloop in bg.tloop_iterator():\n",
    "        for rn in bg.define_residue_num_iterator(tloop):\n",
    "            seq = seq[:rn - 1] + 'E' + seq[rn:]\n",
    "    for i, nucleotide in enumerate(seq):\n",
    "        if nucleotide not in ['S', 'I', 'M', 'H', 'E']:\n",
    "            seq = seq[:i] + 'E' + seq[i + 1:]\n",
    "    return seq\n",
    "\n",
    "def get_loop_type(row):\n",
    "    bg, = forgi.load_rna(row['structure'])\n",
    "    labeled_seq = label_sequence(row['sequence'], bg)\n",
    "    return labeled_seq\n",
    "\n",
    "def parallel_apply(df_chunk):\n",
    "    df_chunk_copy = df_chunk.copy()\n",
    "    df_chunk_copy['predicted_loop_type'] = df_chunk_copy.apply(get_loop_type, axis=1)\n",
    "    return df_chunk_copy\n",
    "\n",
    "# Estimate memory usage of a single row in the DataFrame\n",
    "sample_row = result_df.iloc[0:1]\n",
    "sample_row_mem = sample_row.memory_usage(index=True, deep=True).sum()\n",
    "\n",
    "# Calculate a reasonable chunk size based on available memory and individual row memory usage\n",
    "total_memory = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')\n",
    "max_chunk_size = int(0.8 * (total_memory / sample_row_mem))\n",
    "chunk_size = min(max_chunk_size, len(result_df) // os.cpu_count())\n",
    "print(f'Chunk size: {chunk_size}')\n",
    "\n",
    "# Split DataFrame into chunks based on the adjusted chunk size\n",
    "df_chunks = [result_df[i:i + chunk_size] for i in range(0, len(result_df), chunk_size)]\n",
    "\n",
    "# Parallel computation with tqdm progress bar\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    results = []\n",
    "    for result in tqdm(executor.map(parallel_apply, df_chunks), total=len(df_chunks), desc='Processing'):\n",
    "        results.append(result)\n",
    "\n",
    "result_df = pd.concat(results, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f0c7c-1643-4fc2-be95-709cb547efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sneak peak\n",
    "print(result_df.shape)\n",
    "if ~ result_df.isnull().values.any(): print('No missing values')\n",
    "result_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20217408-71bb-4fe4-ad04-8c712ca5ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('../data/train_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
