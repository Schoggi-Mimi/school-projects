{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas scikit-learn matplotlib datasets transformers wandb seaborn captum ipywidgets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACK = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "if TRACK:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train = load_dataset(\"ai2_arc\", 'ARC-Easy', split='train').to_pandas()\n",
    "test = load_dataset(\"ai2_arc\", 'ARC-Easy', split='test').to_pandas()\n",
    "dev = load_dataset(\"ai2_arc\", 'ARC-Easy', split='validation').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, BertConfig, BertForMultipleChoice\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "SEED = 2023\n",
    "def seed_everything(seed=2023):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Model is in device: {device}')\n",
    "\n",
    "#model_name = 'bert-base-uncased'\n",
    "model_name= 'dmis-lab/biobert-base-cased-v1.1-squad'\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_name).to(device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#print(model_biobert.config)\n",
    "print(f'Model {model.config._name_or_path} is being used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiple_choice_processor import MultipleChoiceProcessor\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "processor = MultipleChoiceProcessor(tokenizer, train[:10], dev[:10], test[:10], set='easy')\n",
    "train_loader, val_loader, test_loader = processor.create_datasets(batch_size=BATCH_SIZE, train_batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train_eval import TrainingPipeline\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CyclicLR\n",
    "from transformers import get_scheduler\n",
    "\n",
    "EPOCHS = 6\n",
    "LR = 0.0001\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=0.3)\n",
    "scheduler = CyclicLR(optimizer, base_lr=LR/10, max_lr=LR, cycle_momentum=False, mode='triangular2')\n",
    "\n",
    "training_pipeline = TrainingPipeline(model, device, train_loader, val_loader, optimizer=optimizer, scheduler=scheduler, \n",
    "                                     track=TRACK, num_epochs=EPOCHS, lr=LR, model_checkpoint=False)\n",
    "\n",
    "train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list = training_pipeline.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline.confusion_matrix(report=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salience Maps: Create visualizations that highlight important tokens or regions in the text. These maps can emphasize the most influential parts of the question and answer choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot import LossAccuracyPlotter\n",
    "\n",
    "plotter = LossAccuracyPlotter(train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, EPOCHS)\n",
    "plotter.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = training_pipeline.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import LayerIntegratedGradients\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "\n",
    "def tokenize(tokenizer, question, answer, max_length=45): #43\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        question,\n",
    "        answer,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    input_ids = encoded_dict['input_ids']\n",
    "    cls_token_id = tokenizer.cls_token_id\n",
    "    sep_token_id = tokenizer.sep_token_id\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    baseline = torch.zeros_like(input_ids)\n",
    "    baseline[input_ids == cls_token_id] = cls_token_id\n",
    "    baseline[input_ids == sep_token_id] = sep_token_id\n",
    "    baseline[(input_ids != cls_token_id) & (input_ids != sep_token_id) & (input_ids != pad_token_id)] = 0\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoded_dict['input_ids'],\n",
    "        'token_type_ids': encoded_dict['token_type_ids'],\n",
    "        'position_ids': encoded_dict['attention_mask'], \n",
    "        'attention_mask': encoded_dict['attention_mask'],\n",
    "        'baseline': baseline,\n",
    "        'answer': answer\n",
    "    }\n",
    "def predict(inputs, token_type_ids=None, position_ids=None, attention_mask=None):\n",
    "    output = model(inputs, token_type_ids=token_type_ids,\n",
    "                     position_ids=position_ids, attention_mask=attention_mask)\n",
    "    return output.start_logits, output.end_logits\n",
    "\n",
    "def squad_pos_forward_func(inputs, token_type_ids=None, position_ids=None, attention_mask=None, position=0):\n",
    "    pred = predict(inputs,\n",
    "                   token_type_ids=token_type_ids,\n",
    "                   position_ids=position_ids,\n",
    "                   attention_mask=attention_mask)\n",
    "    pred = pred[position]\n",
    "    return pred.max(1).values\n",
    "def summarize_attributions(attributions):\n",
    "    attributions = attributions.sum(dim=-1).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    return attributions\n",
    "\n",
    "model_path = 'bert-base-uncased'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForQuestionAnswering.from_pretrained(model_path).to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "#question = 'A hiker wants to know if air is warmer in a forest than in the nearby farm field. Which activity would best help the hiker find out which area is warmer?'\n",
    "#answer = [\n",
    "#    'reading a book about farm fields',\n",
    "#    'making a weather prediction for the forests',\n",
    "#    'measuring the wind speed at both locations',\n",
    "#    'recording the temperatures at both locations'\n",
    "#]\n",
    "question = 'A small aluminum cube is dropped into a beaker of water to determine the buoyancy. Which of these is not necessary in determining the buoyant force acting on the cube?'\n",
    "answer = [\n",
    "    'density of water',\n",
    "    'displaced volume',\n",
    "    'gravitational pull on Earth',\n",
    "    'density of the aluminum cube'\n",
    "]\n",
    "\n",
    "choices = ['A', 'B', 'C', 'D']\n",
    "print(f'Question: {question}')\n",
    "print('Answer Choices:')\n",
    "for i, choice in enumerate(answer):\n",
    "    print(f'\\t[{choices[i]}]: {choice}')\n",
    "\n",
    "for i, choice_text in enumerate(answer):\n",
    "    print(f\"Visualizations for Answer {choices[i]}\")\n",
    "    sample = tokenize(tokenizer, question, choice_text)\n",
    "\n",
    "    input_ids = sample['input_ids'].to(device)\n",
    "    token_type_ids = sample['token_type_ids'].to(device)\n",
    "    position_ids = sample['position_ids'].to(device)\n",
    "    attention_mask = sample['attention_mask'].to(device)\n",
    "    baseline = sample['baseline'].to(device)\n",
    "    answer_text = sample['answer']\n",
    "\n",
    "    lig = LayerIntegratedGradients(squad_pos_forward_func, layer=model.bert.embeddings)\n",
    "\n",
    "    attributions_start, delta_start = lig.attribute(inputs=input_ids,\n",
    "                                                   baselines=baseline,\n",
    "                                                   additional_forward_args=(token_type_ids, position_ids, attention_mask, 0),\n",
    "                                                   return_convergence_delta=True)\n",
    "    attributions_end, delta_end = lig.attribute(inputs=input_ids,\n",
    "                                                 baselines=baseline,\n",
    "                                                 additional_forward_args=(token_type_ids, position_ids, attention_mask, 1),\n",
    "                                                 return_convergence_delta=True)\n",
    "\n",
    "    attributions_start_sum = summarize_attributions(attributions_start)\n",
    "    attributions_end_sum = summarize_attributions(attributions_end)\n",
    "    start_scores, end_scores = predict(input_ids, token_type_ids=token_type_ids, position_ids=position_ids, attention_mask=attention_mask)\n",
    "    ground_truth_tokens = tokenizer.encode(answer_text, add_special_tokens=False)\n",
    "    indices = input_ids[0].detach().tolist()\n",
    "    all_tokens = tokenizer.convert_ids_to_tokens(indices)\n",
    "    ground_truth_end_ind = indices.index(ground_truth_tokens[-1])\n",
    "    ground_truth_start_ind = ground_truth_end_ind - len(ground_truth_tokens) + 1\n",
    "\n",
    "    start_position_vis = viz.VisualizationDataRecord(\n",
    "                            attributions_start_sum,\n",
    "                            torch.max(torch.softmax(start_scores[0], dim=0)),\n",
    "                            torch.argmax(start_scores),\n",
    "                            torch.argmax(start_scores),\n",
    "                            str(ground_truth_start_ind),\n",
    "                            attributions_start_sum.sum(),       \n",
    "                            all_tokens,\n",
    "                            delta_start)\n",
    "    end_position_vis = viz.VisualizationDataRecord(\n",
    "                            attributions_end_sum,\n",
    "                            torch.max(torch.softmax(end_scores[0], dim=0)),\n",
    "                            torch.argmax(end_scores),\n",
    "                            torch.argmax(end_scores),\n",
    "                            str(ground_truth_end_ind),\n",
    "                            attributions_end_sum.sum(),       \n",
    "                            all_tokens,\n",
    "                            delta_end)\n",
    "    print('\\033[1m', f'Visualizations For Start Position - Answer {choices[i]}', '\\033[0m')\n",
    "    viz.visualize_text([start_position_vis])\n",
    "\n",
    "    print('\\033[1m', f'Visualizations For End Position - Answer {choices[i]}', '\\033[0m')\n",
    "    viz.visualize_text([end_position_vis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
